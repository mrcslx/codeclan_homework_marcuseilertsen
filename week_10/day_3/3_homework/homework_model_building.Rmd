---
title: 'Manual model development'
output:
  html_document:
    toc: true
    toc_float: true
    number_sections: true
    df_print: paged
  pdf_document: default
---


# MVP

You are given a set of data on housing sale prices for the last few years in King County (near Seattle) between May 2014 and May 2015.

<br>
<div class="emphasis">
We want you to build an **explanatory model** for the `price` of housing in King County, i.e. an interpretable model in which the included variables are statistically justifiable.

The variable definitions are:

`id` - Unique ID for each home sold  
`date` - Date of the home sale  
`price` - Price of each home sold  
`bedrooms` - Number of bedrooms  
`bathrooms` - Number of bathrooms, where .5 accounts for a room with a toilet but no shower  
`sqft_living` - Square footage of the apartments interior living space  
`sqft_lot` - Square footage of the land space  
`floors` - Number of floors  
`waterfront` - A dummy variable for whether the apartment was overlooking the waterfront or not  
`view` - An index from 0 to 4 of how good the view of the property was  
`condition` - An index from 1 to 5 on the condition of the apartment  
`grade` - An index from 1 to 13, where 1-3 falls short of building construction and design, 7 has an average level of construction and design, and 11-13 have a high quality level of construction and design  
`sqft_above` - The square footage of the interior housing space that is above ground level  
`sqft_basement` - The square footage of the interior housing space that is below ground level  
`yr_built` - The year the house was initially built  
`yr_renovated` - The year of the houseâ€™s last renovation  
`zipcode` - What zipcode area the house is in  
`lat` - Latitude  
`long` - Longitude  
`sqft_living15` - The square footage of interior housing living space for the nearest 15 neighbors  
`sqft_lot15` - The square footage of the land lots of the nearest 15 neighbors  
</div>
<br>

```{r}
library(tidyverse)
library(modelr)
library(ggfortify)
library(GGally)
```

```{r}
kc_house_data <- read_csv("data/kc_house_data.csv")
```


# Question 1

Tidy up the data ready for regression:

    * You might like to think about removing some or all of `date`, `id`, `sqft_living15`, `sqft_lot15` and `zipcode` (`lat` and `long` provide a better measure of location in any event).
    * Have a think about how to treat `waterfront`. Should we convert its type?
    * We converted `yr_renovated` into a `renovated` logical variable, indicating whether the property had ever been renovated. You may wish to do the same.
    * Have a think about how to treat `condition` and `grade`? Are they interval or categorical ordinal data types?

<br>

```{r}
houses_tidy <- kc_house_data %>% 
  mutate(waterfront = as.logical(waterfront)) %>% 
  mutate(renovated = as.logical(yr_renovated)) %>% 
  select(-c(date, id, sqft_living15, sqft_lot15, zipcode, yr_renovated))
```

<br>

# Question 2

Check for aliased variables using the `alias()` function (this takes in a formula object and a data set). [**Hint** - formula `price ~ .` says 'price varying with all predictors', this is a suitable input to `alias()`]. Remove variables that lead to an alias. Check the 'Elements of multiple regression' lesson for a dropdown containing further information on finding aliased variables in a dataset.

<br>

```{r}
alias(price ~ ., houses_tidy)
```

We will remove `sqft_above` and `sqft_basement`.

```{r}
houses_tidy <- houses_tidy %>% 
  select(-sqft_basement)
```

<br>

# Question 3

Systematically build a regression model containing up to **four** main effects (remember, a main effect is just a single predictor with coefficient), testing the regression diagnostics as you go
    * splitting datasets into numeric and non-numeric columns might help `ggpairs()` run in manageable time, although you will need to add either a `price` or `resid` column to the non-numeric dataframe in order to see its correlations with the non-numeric predictors.

<details>
<summary>**Hints**</summary>
```{r, eval=FALSE}
houses_tidy_numeric <- houses_tidy %>%
  select_if(is.numeric)

houses_tidy_nonnumeric <- houses_tidy %>%
  select_if(function(x) !is.numeric(x))

houses_tidy_nonnumeric$price <- houses_tidy$price

houses_tidy_numeric_1 <- houses_tidy_numeric %>% 
  select(price:view)

houses_tidy_numeric_2 <- houses_tidy_numeric %>% 
  select(c(price, condition:long))

ggpairs(houses_tidy_numeric_1)
ggpairs(houses_tidy_numeric_2)
ggpairs(houses_tidy_nonnumeric)
```


```{r}
colSums(is.na(houses_tidy))
```


First Model

```{r}
mod1a <- lm(price ~ sqft_living, 
            data = houses_tidy)

autoplot(mod1a)

summary(mod1a)
```

Looks bad, cone shape.

```{r}
mod1b <- lm(price ~ grade, 
            data = houses_tidy)

autoplot(mod1b)

summary(mod1b)
```


```{r}
mod1c <- lm(price ~ bathrooms, 
            data = houses_tidy)

autoplot(mod1c)

summary(mod1c)
```


```{r}
mod1d <- lm(price ~ waterfront, 
            data = houses_tidy)

autoplot(mod1d)

summary(mod1d)
```


```{r}
mod1e <- lm(price ~ sqft_above, 
            data = houses_tidy)

autoplot(mod1e)

summary(mod1e)
```


```{r}
model_1 <- mod1a # price ~ sqft_living
```

We can explain 49%, now we are looking for the remaining 51% through residuals.

```{r}
houses_remaining_resid <- houses_tidy %>% 
  add_residuals(model_1) %>% 
  select(-price, -sqft_living)

houses_remaining_resid_1 <- houses_remaining_resid %>% 
  select(c(bedrooms:view, resid))

houses_remaining_resid_2 <- houses_remaining_resid %>% 
  select(condition:resid)
```

We are trying to explain the residuals by using predictors other than `education`.

```{r}
houses_remaining_resid_1 %>% 
  ggpairs()

houses_remaining_resid_2 %>% 
  ggpairs()
```

Second Model

```{r}
mod2a <- lm(price ~ sqft_living + lat, 
            data = houses_tidy)

autoplot(mod2a)

summary(mod2a)
```


```{r}
mod2b <- lm(price ~ sqft_living + view, 
            data = houses_tidy)

autoplot(mod2b)

summary(mod2b)
```


and the same in subsequent rounds of predictor selection with the `resid` column.<br><br>
Remember, if you are not sure whether including a categorical predictor is statistically justified, run an `anova()` test passing in the models with- and without the categorical predictor and check the p-value of the test.
</details>



# Extensions

* Consider possible interactions between your four main effect predictors and test their effect upon $r^2$. Choose your best candidate interaction and visualise its effect. 

* Calculate the relative importance of predictors from your best $4$-predictor model (i.e. the model without an interaction). Which predictor affects `price` most strongly?

